#+Title: Extending BanditFuzz: Towards Comprehensive Testing of SMT-Solvers
#+Author: Michael Lynch (20852964) and Shadman Raihan (20858688)
#+OPTIONS: toc:nil
#+OPTIONS: num:nil
#+OPTIONS: \n:t
#+LATEX_CLASS_OPTIONS: [article,11pt]

#+LATEX_HEADER: \usepackage[left=18mm,right=18mm,top=25mm,bottom=25mm]{geometry}
#+LATEX_HEADER: \setlength{\columnsep}{5mm}
#+LATEX_HEADER: \usepackage{comment}
#+LATEX_HEADER: \usepackage[ruled, linesnumbered, boxed]{algorithm2e}


# Novelty, execution, potential for impact

* Abstract
# Write at the end
* Introduction
** Problem Statement
*** 
Software testing has advanced substantially in the 50 or so years since software engineering became an established discipline but it still proves to be a challenge as software grows more complex.  
As with any engineering activity, creating and using software involves an element of risk, which can be mitigated, but not eliminated entirely. Faults in software can lead to a range of consequences, from loss of consumer confidence, financial penalties and in the most extreme cases, the loss of human life.
The cost of finding and repairing faults is five times larger\cite{bk:amman} in the deployment phase compared to the system testing phase and about fifty times larger\cite{bk:amman} than in the development and unit testing phase. Therefore, it is in the best interests of both organizations and their clients to ensure that software is tested early and well.  
Quantifiying the complexity of code is difficult but can be achieved somewhat by creating a graph of the program execution and analyzing unique paths\cite{bk:amman}. However every conditional statement results in at least a doubling of subsequent paths and thus, a program with $n$ conditionals will have $O(2^n)$ possible paths. In 2015, Google had approximately 2 billion lines of code\cite{vid:googlecode} and an exponentially increasing number of commits per year, with approximately 30 million between 2010 and 2015 alone\cite{vid:googlecode}. Obviously, this is impossible to test manually, and even automated testing would struggle with such a large number of paths. The fact that some paths may only be accessible when certain inputs are provided adds another layer of complexity to the problem, so tools that can make this process more tractable are necessary.  
*** SAT/SMT solvers
The Satisfiable Modulo Theories problem (SMT) is a decision problem which can be stated as follows\cite{notes:lec17}:
- Given a formula $\phi$ in an algebra $\Sigma$, does there exist a variable assignment $\iota$ such that $\Sigma,\iota\models \phi$ ?
When $\Sigma$ is the Boolean algebra, this reduces to the Boolean satisfiability (SAT) problem. 


Solvers are also usually designed to return $\iota$, which is usually the focus of the problem in practical applications.
- their use as TAV tools
*** Fuzzing
- fuzz testing and why it is useful
- the drawbacks of fuzz testing (grammars)
- testing SAT/SMT solvers
- why is it hard?
- why test solvers other than its good practice?
- guided/smart fuzz testing
- banditfuzz
# ==== REWRITE THIS VVV
Fuzz testing is well suited to locating the types of problems described above, but a naive approach fails for a few reasons.   
- Since SMT solvers analyze computer programs, they necessarily expect input in a formal language, restricting the possible inputs to that generated from a specified alphabet with a context-free grammar.
- A randomly constructed input is highly unlikely to be well-formed.
- Even with full knowledge of the alphabet and grammar, there are an infinite number of possible constructs in the language.
The problem of fuzzing an SMT solver then becomes: given a formal language $L$, find those words in $L$ which elicit malicious behaviour upon input to the solver.   
The BanditFuzz\cite{bandit} fuzzer solves these problems by combining the grammar-aware approach of mutational fuzzing with reinforcement learning techniques to rapidly locate inputs detrimental to performance. Typical mutation fuzzers do not utilise feedback, therefore wasting valuable information gained from program behaviour.  
Although BanditFuzz has proven extremely successful in solving this problem, it still permits further extension and optimization which is the focus of this project.  
Firstly, BanditFuzz should be extended to support more of the primitives outlined in the SMT-Lib standard \cite{SMT}, namely bit vectors, although arrays and algebraic primitives could be considered with further research.  
# ==== REWRITE THIS ^^^
- limitations of banditfuzz
- 

** Relevance
- SAT solvers extremely useful for verifying

** Description of Work
- implementation of bitvector theory
- connection of the theory to the fuzzer

* Method
** Bitvector Theory
- decription of bitvector theory
- encoding in banditfuzz format (code sample)
- associated challenges
** Description of Algorithm
- description of banditfuzz algorithm for generating inputs
- example of output using bitvector theory
- 
* Results
- inconclusive
* Conclusions and Future Work
- MCMC sampling
# ==== REWRITE THIS VVV
Secondly, as shown in the BanditFuzz paper\cite{bandit}, the mutation with reinforcement learning approach reduces to the multi-armed bandit problem, which suggests that there are multiple approaches to the problem. Therefore, approaches ranging from MCMC sampling to simple graph search algorithms will be evaluated with an aim towards optimizing the operation of the fuzzer. Other metrics such as parallelizability will also be considered, with a view towards practical deployment.
# ==== REWRITE THIS ^^^
- Additional theories
- Refactoring banditfuzz, writing tests

* References
# References go here, will convert to bibtex at some point
- ammann software testing
- BanditFuzz paper
- Look up MCMC techniques
- Bitvectors (SMT-Lib Standard) http://smtlib.cs.uiowa.edu/papers/smt-lib-reference-v2.6-r2017-07-18.pdf
- Beaver https://people.eecs.berkeley.edu/~sseshia/pubdir/beaver-cav09.pdf
- Boolector https://link.springer.com/chapter/10.1007/978-3-642-00768-2_16
- Google Lines of code video https://www.youtube.com/watch?v=W71BTkUbdqE


* Benchmarks
The benchmarks in this paper will be similar to those used in the BanditFuzz paper, with some additions:
To evaluate the bitvector additions a bitvector SMT solver such as Beaver\cite{beaver} or Boolector\cite{boolector} must be used.  
The original BanditFuzz paper\cite{bandit} uses the SMT solvers Z3, CVC4, MathSAT, Colibri which are floating point solvers and Z3str3 which is a string solver. These will be evaluated as in the paper to provide a control.  
The SMT solvers from the BanditFuzz paper will also be used to evaluate any modifications to the reinforcement learning portion.  
If any other primitives are added to BanditFuzz then corresponding SMT solvers must be used.




* Proposed Demonstration
A demonstration of the modified fuzzer will involve performing the same evaluation as given in the BanditFuzz paper\cite{bandit} as a contro, and then evaluations of the modified portions. This would proceed as follows: 
1) Evaluate BanditFuzz on the SMT solvers as given in the original paper, on a restricted number of inputs to save time. The time taken to solve should be logged.
2) Evaluate BanditFuzz with the additional bit-vector, etc functionality on a corresponding solver, for example Beaver, and compare with the performance in step 1).
3) Evaluate BanditFuzz with the modified approach to the multi-armed bandit problem on the same benchmarks given above, comparing and contrasting performance.

